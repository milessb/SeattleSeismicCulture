{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import json\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "import html2text\n",
    "from dateutil.parser import parse as parse_date\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "from bs4 import SoupStrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to directly scrape url links from web page with desired links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search_url = 'http://infoweb.newsbank.com/resources/search/nb?p=WORLDNEWS&b=results&action=search&t=pubname%3ASTIW%21Seattle%2BTimes%252C%2BThe%2B%2528WA%2529&fld0=alltext&val0=fremont+murray+lenin&bln1=AND&fld1=YMD_date&val1=&sort=_rank_%3AD'\n",
    "\n",
    "# parsed_search_url = urlparse(search_url)\n",
    "# root_url = parsed_search_url.scheme + \"://\" + parsed_search_url.hostname\n",
    "\n",
    "# search_string = 'resources/doc/nb/news'\n",
    "\n",
    "# page = requests.get(search_url)\n",
    "\n",
    "# url_list = []\n",
    "\n",
    "# for link in BeautifulSoup(response.content, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "#     if link.has_attr('href'):\n",
    "#         if search_string in link['href']:\n",
    "#             full_path = root_url + link['href']\n",
    "#             url_list.append(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to read in url links from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_list_filename = 'seattle_times_quake_article_urls.txt'\n",
    "\n",
    "with open(url_list_filename, \"rt\") as f:\n",
    "    url_list = [url.strip() for url in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = [requests.get(url).text for url in url_list]\n",
    "soup_pages = [BeautifulSoup(page, \"lxml\") for page in pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape articles form list of url links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for (soup_page, url) in zip(soup_pages, url_list):\n",
    "\n",
    "    article = soup_page.find('div', {'class': 'body'}).text.strip()\n",
    "    article = article.replace('\\n', ' ')\n",
    "\n",
    "    try:\n",
    "        author = soup_page.find('li', {'class': 'author first'}).find_next().find_next().text.strip().title()\n",
    "        if ',' in author:\n",
    "            author = author.replace(re.search(r\"(,.*)\", author, re.I | re.M | re.S).groups()[0], '')\n",
    "        \n",
    "    except:\n",
    "        author = 'Unknown'\n",
    "    \n",
    "    try:\n",
    "        edition = soup_page.find('li', {'class': 'edition'}).find_next().find_next().text.strip().title()\n",
    "    except:\n",
    "        edition = 'Unknown'\n",
    "   \n",
    "    try:\n",
    "        section = soup_page.find('li', {'class': 'section'}).find_next().find_next().text.strip().title()\n",
    "        \n",
    "        if section.lower() == 'local':\n",
    "            section = 'Local News'\n",
    "    except:\n",
    "        section = 'Unknown'\n",
    "\n",
    "    try:\n",
    "        page = soup_page.find('li', {'class': 'page'}).find_next().find_next().text.strip()\n",
    "    except:\n",
    "        page = 'Unknown'\n",
    "\n",
    "    try:\n",
    "        column = soup_page.find('li', {'class': 'column'}).find_next().find_next().text.strip().title()\n",
    "    except:\n",
    "        column = 'Unknown'\n",
    "    \n",
    "    try:\n",
    "        title = soup_page.find('div', {'class': 'title'}).text.strip()\n",
    "        \n",
    "        if title == title.upper():\n",
    "            title = title.capitalize()\n",
    "    \n",
    "        if '/' in title:\n",
    "            title = title.replace('/', '-')\n",
    "   \n",
    "    except:\n",
    "        title = 'Unknown'\n",
    "\n",
    "    try:\n",
    "        date = soup_page.find('div', {'class': 'source'}).text.strip()\n",
    "        \n",
    "        if 'Seattle Times, The (WA) - ' in date:\n",
    "            date = date.replace('Seattle Times, The (WA) - ', '')\n",
    "        if 'Seattle Times, The (WA) (Published as THE SEATTLE TIMES)  - ' in date:\n",
    "            date = date.replace('Seattle Times, The (WA) (Published as THE SEATTLE TIMES)  - ', '')\n",
    "        if 'Browse Issues' in date:\n",
    "            date = date.replace('Browse Issues', '')\n",
    "        \n",
    "        date = parse_date(date).strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        date = 'Unknown'\n",
    "\n",
    "    folder = 'SeattleTimesQuakeArticles/json/'\n",
    "    filename = (date + '_' + \n",
    "        title[:100].title().replace(' ', '').replace(',', '').replace(\"'\", \"\").replace('?', '').replace('.', '').replace(';', '').replace(':', '') + \n",
    "        '.json')\n",
    "    file_path = folder + filename\n",
    "\n",
    "    article_dict = {\n",
    "                'title' : title,\n",
    "                'date' : date,\n",
    "                'author' : author,\n",
    "                'edition': edition,\n",
    "                'section' : section,\n",
    "                'page' : page,\n",
    "                'text' : article,\n",
    "                'filename' : filename,\n",
    "                'url' : url\n",
    "            }\n",
    "\n",
    "    articles.append(article_dict)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(article_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out metadata about a few of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles:  2079\n",
      "----------------------------- \n",
      "\n",
      "Fund earthquake\n",
      "2017-06-05\n",
      "Seattle Times Editorial Board\n",
      "Editorial\n",
      "A13\n",
      "2017-06-05_FundEarthquake.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/164D41CE27B17408?p=WORLDNEWS\n",
      "America provides for the common defense of its people in many ways, and not all involve the military. One inexpensive way to protect millions of citizens is to warn them of major earthquakes, which ar\n",
      "======================================== \n",
      "\n",
      "Earthquake early-alert system in jeopardy\n",
      "2017-05-27\n",
      "Rong-Gong Lin Ii\n",
      "News\n",
      "A1\n",
      "2017-05-27_EarthquakeEarly-AlertSystemInJeopardy.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/164BCEAC4C0898D0?p=WORLDNEWS\n",
      "LOS ANGELES — President Donald Trump’s budget proposal would cut federal funding for an earthquake early-warning system for California, Oregon and Washington state, a development that seismology exper\n",
      "======================================== \n",
      "\n",
      "Ride out a fake  quake, typhoon: Theme parks give jolt of urgency\n",
      "2017-05-15\n",
      "Sandi Doughton\n",
      "Local News\n",
      "A1\n",
      "2017-05-15_RideOutAFakeQuakeTyphoonThemeParksGiveJoltOfUrgency.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/16465BA122DB5AE8?p=WORLDNEWS\n",
      "KOBE, Japan — Somehow, it’s not surprising that the country that gave us Godzilla and elevated fake food to a fine art has also found a way to make earthquake preparedness entertaining. Guided by the \n",
      "======================================== \n",
      "\n",
      "Little action on quake preparedness\n",
      "2017-05-07\n",
      "Sandi Doughton\n",
      "Local News\n",
      "B1\n",
      "2017-05-07_LittleActionOnQuakePreparedness.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/1643C58F91BD07E8?p=WORLDNEWS\n",
      "The day after convening a subCabinet meeting on earthquake preparedness last week, Gov. Jay Inslee signed the single seismic-safety bill passed by the Legislature this session. The original bill would\n",
      "======================================== \n",
      "\n",
      "Q&A: nine things to know about earthquake insurance\n",
      "2016-12-18\n",
      "Unknown\n",
      "Local News\n",
      "A16\n",
      "2016-12-18_Q&ANineThingsToKnowAboutEarthquakeInsurance.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/1616917B771618B8?p=WORLDNEWS\n",
      "Question: I have homeowners insurance. That also covers me for earthquakes, right? Answer: Don’t bet on it. Earthquake insurance typically needs to be purchased in addition to a homeowner policy. Read\n",
      "======================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles: ', len(articles))\n",
    "print('-----------------------------', '\\n')\n",
    "for art in articles[:5]:\n",
    "    print(art['title'])\n",
    "    print(art['date'])\n",
    "    print(art['author'])\n",
    "    print(art['section'])\n",
    "    print(art['page'])\n",
    "    print(art['filename'])\n",
    "    print(art['url'])\n",
    "    print(art['text'][:200])\n",
    "    print('========================================', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to make sure can read in a generated json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murray calls for removal of monument and statue\n",
      "2017-08-18\n",
      "Paige Cornwell\n",
      "Local News\n",
      "B1\n",
      "2017-08-18_MurrayCallsForRemovalOfMonumentAndStatue.json\n",
      "http://infoweb.newsbank.com/resources/doc/nb/news/1665A81FD98D65A8?p=WORLDNEWS\n",
      "Seattle Mayor Ed Murray has called for both the monument to Confederate soldiers at Capitol Hill’s Lake View Cemetery and a statue of Vladimir Lenin in Fremont to be taken down, saying they represent \n"
     ]
    }
   ],
   "source": [
    "with open(articles[0]['filename'], 'r') as f:\n",
    "     test_json_file = json.load(f)\n",
    "\n",
    "test_json_file['title']\n",
    "print(test_json_file['title'])\n",
    "print(test_json_file['date'])\n",
    "print(test_json_file['author'])\n",
    "print(test_json_file['section'])\n",
    "print(test_json_file['page'])\n",
    "print(test_json_file['filename'])\n",
    "print(test_json_file['url'])\n",
    "print(test_json_file['text'][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
